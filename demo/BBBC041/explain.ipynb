{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import hshap\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# select device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "torch.set_grad_enabled(False)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# load pretrained model\n",
    "model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet18\", pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.load_state_dict(torch.load(\"model.pt\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset transform\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "# load reference\n",
    "ref = torch.load(\"reference.pt\")\n",
    "ref = ref.to(device)\n",
    "\n",
    "# load annoations\n",
    "annotations = pd.read_json(\"annotations.json\")\n",
    "\n",
    "# define annotation function\n",
    "def annotate(ax, filename):\n",
    "    query = annotations.loc[annotations[\"image\"] == filename]\n",
    "    for i, row in query.iterrows():\n",
    "        trophozoites = row[\"objects\"]\n",
    "        for trophozoite in trophozoites:\n",
    "            bbox = trophozoite[\"bounding_box\"]\n",
    "            upper_left_r = bbox[\"minimum\"][\"r\"]\n",
    "            upper_left_c = bbox[\"minimum\"][\"c\"]\n",
    "            lower_right_r = bbox[\"maximum\"][\"r\"]\n",
    "            lower_right_c = bbox[\"maximum\"][\"c\"]\n",
    "            w = np.abs(lower_right_c - upper_left_c)\n",
    "            h = np.abs(lower_right_r - upper_left_r)\n",
    "            rect = patches.Rectangle(\n",
    "                (upper_left_c, upper_left_r),\n",
    "                w,\n",
    "                h,\n",
    "                linewidth=2,\n",
    "                edgecolor=\"g\",\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize h-Shap explainer\n",
    "s = 80\n",
    "hexp = hshap.src.Explainer(model, ref)\n",
    "\n",
    "# define thresholding modes\n",
    "threshold_mode = \"absolute\"\n",
    "threshold = 0\n",
    "# for each example image\n",
    "for (dirpath, _, filenames) in os.walk(\"images\"):\n",
    "    for filename in tqdm(filenames):\n",
    "        # prepare figure\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        # load and transform image\n",
    "        image_path = os.path.join(dirpath, filename)\n",
    "        image = Image.open(image_path)\n",
    "        image_t = transform(image).to(device)\n",
    "\n",
    "        # show original image\n",
    "        ax = axes[0]\n",
    "        ax.imshow(np.array(image))\n",
    "        annotate(ax, filename)\n",
    "        ax.set_title(\"Original image\")\n",
    "\n",
    "        # explain image\n",
    "        explanation = hexp.explain(\n",
    "            image_t,\n",
    "            label=1,\n",
    "            threshold_mode=threshold_mode,\n",
    "            threshold=threshold,\n",
    "            batch_size=1,\n",
    "        )\n",
    "        explanation.squeeze_()\n",
    "\n",
    "        # show explanation\n",
    "        ax = axes[1]\n",
    "        _abs = np.abs(explanation.flatten())\n",
    "        _max = max(_abs)\n",
    "        ax.imshow(explanation, cmap=\"bwr\", vmax=_max, vmin=-_max)\n",
    "        annotate(ax, filename)\n",
    "        ax.set_title(\n",
    "            r\"h-Shap ($\\tau = %.0f%s,~s = %d$ pixels)\"\n",
    "            % (threshold, \"\\%\" if threshold_mode == \"relative\" else \"\", s)\n",
    "        )\n",
    "        img_id = filename.split(\".\")[0]\n",
    "\n",
    "        # save figure\n",
    "        plt.savefig(os.path.join(\"explanations\", f\"{img_id}.jpg\"))\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('cuda116')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "630ee23c61ae49ff9b1bba0e9549dd77f2e45981cb6c257dfd38d68903b0a003"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "a22ede1198d678ad2a1cff9cda8d5b8766f1097d9385ad651df4552564969b5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
